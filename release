#!/usr/bin/env python3

from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())

import shlex
from packaging import version as vcomp
import boto3
from munch import Munch
from urllib.request import urlopen, urlretrieve
import json
import os
import argparse
import toml
import sys
from datetime import date
import shutil
import tarfile
import re
import configparser
import lxml.etree as etree
from lxml.builder import ElementMaker
import glob
import github3 as github
import mimetypes
import subprocess
import textwrap
from string import Template
from pydpkg import Dpkg
from arpy import ArchiveFormatError

parser = argparse.ArgumentParser()
parser.add_argument('--bump', action='store_true')
parser.add_argument('--reload', action='store_true')
parser.add_argument('--rebuild', action='store_true')
args = parser.parse_args()
if args.reload or os.environ.get('REBUILD', '').strip() != '': args.rebuild = True

#### global data ####
with open('config.toml') as f:
  Config = toml.load(f, _dict=Munch)

ArchMap = {
  'i686': 'i386',
  'x86_64': 'amd64'
}

def get_clients():
  clients = []
  for section, values in Config.items():
    if 'name' in values and 'comment' in values: clients.append(section)
  return clients
Clients = get_clients()

def pluralize(d, singular):
  plural = singular + 's'
  assert not (singular in d and plural in d)
  if singular in d:
    d[plural] = d[singular]
    del d[singular]
  if plural in d and type(d[plural]) != list:
    d[plural] = [ d[plural] ]

def load_mimeinfo():
  with open('mimeinfo.toml') as f:
    _mimeinfo = toml.load(f, _dict=Munch)
    for mi in _mimeinfo.values():
      for singular in ['mimetype', 'extension']:
        plural = singular + 's'
        assert not (singular in mi and plural in mi)
        if singular in mi:
          mi[plural] = mi[singular]
          del mi[singular]
        if plural in mi and type(mi[plural]) != list:
          mi[plural] = [ mi[plural] ]
      
      if 'extensions' in mi:
        mi['extensions'] = [ext[1:] if ext[0] == '.' else ext for ext in mi['extensions']]
  return _mimeinfo
MimeInfo = load_mimeinfo()

def load_esr_deps():
  deps = []
  for dep in os.popen('apt-cache depends firefox-esr').read().split('\n'):
    dep = dep.strip()
    if not dep.startswith('Depends:'): continue
    dep = dep.split(':')[1].strip()
    if dep != 'lsb-release': # why should it need this?
      deps.append(dep)
  return deps
ESR = load_esr_deps()

#### convenience functions ####

class Repository:
  def __init__(self):
    self.rebuild = 'Packages' not in self._assets # deleting 'Packages' forces re-uploading of everything
    if self.rebuild:
      for asset in self._assets.values():
        self.delete(asset)
      self._assets = {}

  def unchanged(self):
    published = set([asset for asset in self._assets.keys() if asset.endswith('.deb')])
    available = set([os.path.basename(deb.deb) for deb in Deb.all()])
    return published == available

class GitHub(Repository):
  def __init__(self, config):
    self.service = 'github'
    self.url = f'https://github.com/{config.repo}/releases/download/{config.release}'

    gh = github.GitHub(token=os.getenv('GITHUB_TOKEN'), session=github.session.GitHubSession(default_read_timeout=60))
    repo = gh.repository(*config.repo.split('/'))

    self._release = repo.release_from_tag(config.release)
    self._assets = { asset.name: asset for asset in self._release.assets() }

    super().__init__()

  def delete(self, asset):
    asset.delete()

  def get(self, name):
    if not name.endswith('.deb'): return False

    asset = self._assets.get(os.path.basename(name))
    if asset:
      os.makedirs(os.path.dirname(name), exist_ok=True)
      #urlretrieve(asset.download_url, name)
      run(f'curl -s -L -o {shlex.quote(name)} {shlex.quote(asset.download_url)}')
      return True
    return False

  def publish(self):
    print(f'\n## publishing repo to github')
    published = []
    for asset in self._release.assets():
      if not os.path.exists(f'repo/{asset.name}'):
        print('  deleting obsolete asset:', asset.name)
        asset.delete()
      elif asset.name.endswith('.deb') and not args.rebuild:
        published.append(asset.name)
      else:
        print('  refreshing asset:', asset.name)
        asset.delete()

    for asset in sorted(glob.glob('repo/*')):
      if os.path.basename(asset) in published: continue

      content_type = mimetypes.guess_type(asset)[0] or 'application/octet-stream'
      print(f'  uploading {asset} ({content_type})')
      with open(asset, 'rb') as f:
        self._release.upload_asset(
          asset=f,
          name=os.path.basename(asset),
          content_type=content_type
        )

class S3:
  def __init__(self, config):
    self.service = 's3'
    self.url = f'https://{config.bucket}.s3.{config.region}.amazonaws.com'

    s3 = boto3.resource('s3')
    self._bucket = s3.Bucket(name=config.bucket)
    self._assets = { asset.key: asset for asset in self.bucket.objects.all() }

    super().__init__()

  def delete(self, asset):
    self._bucket.delete_key(asset)
    
  def get(self, name):
    if not name.endswith('.deb'): return False

    try:
      for asset in self.bucket.objects.all():
        if os.path.basename(asset.key) == os.path.basename(name):
          self.bucket.download_file(os.path.basename(name), name)
          return True
    except:
      print('  error: could not get {os.path.basename(name)}')
      if os.path.exists(name): os.remove(name)

    return False

  def publish(self):
    print(f'\n## publishing repo to S3 bucket')
    published = []
    for asset in self.bucket.objects.all():
      if not os.path.exists(f'repo/{asset.key}'):
        print('  deleting obsolete asset:', asset.key)
        self.bucket.delete_key(asset)
      elif asset.key.endswith('.deb') and not args.rebuild:
        published.append(asset.key)
      else:
        print('  refreshing asset:', asset.key)

    for asset in sorted(glob.glob('repo/*')):
      if os.path.basename(asset) in published: continue

      content_type = mimetypes.guess_type(asset)[0] or 'application/octet-stream'
      print(f'  uploading {asset} ({content_type})')
      self.bucket.upload_file(asset, os.path.basename(asset))

def load_repo():
  branch = os.environ.get('GITHUB_REF', '')
  branch = branch.split('/')[-1] if branch.startswith('refs/heads/') else None
  repo = None
  print(f'\n## branch = {branch}')
  if branch and branch in Config:
    for hosting, config in [(h.lower(), data) for h, data in Config[branch].items() if h.lower() in ('github', 's3')]:
      if hosting == 'github':
        print('\n## publish target: Github release')
        repo = GitHub(config)
      elif hosting == 's3':
        print('\n## publish target: S3 bucket')
        repo = S3(config)
      break

  if not repo:
    print(f'  no repo found for {branch}')
  return repo
Repo = load_repo()

def run(cmd):
  print('  $', cmd)

  try:
   print(textwrap.indent(subprocess.check_output(cmd, shell=True).decode('utf-8'), '    '))
  except subprocess.CalledProcessError as e:
    print(textwrap.indent(e.output.decode('utf-8'), '    '))
    sys.exit(1)

class Open():
  def __init__(self, path, mode='r', fmode=None):
    if 'w' in mode or 'a' in mode: os.makedirs(os.path.dirname(path), exist_ok=True)
    self.path = path
    self.mode = fmode
    self.f = open(path, mode)
  def __enter__(self):
    return self.f
  def __exit__(self, exc_type, exc_value, exc_traceback):
    self.f.close()
    if self.mode is not None:
      os.chmod(self.path, self.mode)

def load(url,parse_json=False):
  response = urlopen(url).read()
  if type(response) is bytes: response = response.decode('utf-8')
  if parse_json:
    return json.loads(response, object_hook=Munch.fromDict)
  else:
    return response

class Version:
  def __init__(self, deb, *args):
    self.deb  = deb
  def __lt__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) < vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client < other.deb.client
  def __gt__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) > vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client > other.deb.client
  def __eq__(self, other):
    return self.deb.client == other.deb.client and vcomp.parse(self.deb.version.replace('m', '.')) == vcomp.parse(other.deb.version.replace('m', '.'))
  def __le__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) <= vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client <= other.deb.client
  def __ge__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) >= vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client >= other.deb.client
  def __ne__(self, other):
    return self.deb.client != other.deb.client and vcomp.parse(self.deb.version.replace('m', '.')) != vcomp.parse(other.deb.version.replace('m', '.'))

class Deb:
  __debs = []

  @classmethod
  def select(cls, version = None, client = None, arch=None, aptarch=None, beta=True):
    def equal(deb):
      return (version is None or version == deb.version) and (client is None or client == deb.client) and (arch is None or arch == deb.arch) and (aptarch is None or aptarch == deb.apt.arch) and (beta or not deb.beta)
    #print('version:', version, 'client:', client, 'arch:', arch, 'aptarch:', aptarch, 'beta:', beta)
    #for deb in cls.__debs:
    #  if equal(deb):
    #    print('== version:', deb.version, 'client:', deb.client, 'arch:', deb.arch, 'aptarch:', deb.apt.arch, 'beta:', deb.beta)
    #  else:
    #    print('!=',
    #      'version:', deb.version, 
    #      'client:', deb.client, 
    #      'arch:', deb.arch,
    #      'aptarch:', deb.apt.arch,
    #      'beta:', deb.beta
    #    )

    return sorted([deb for deb in cls.__debs if equal(deb)], key=Version)

  @classmethod
  def all(cls):
    return cls.select()

  @classmethod
  def rebuilt(cls):
    return any(deb for deb in cls.__debs if deb.rebuilt)

  def __init__(self, client, version, arch):
    Deb.__debs.append(self)

    self.rebuilt = False

    self.client = client
    self.version = version
    self.arch = arch
    self.beta = version.startswith('beta-')

    # set download URL
    self.url = {
      'zotero':       f'https://www.zotero.org/download/client/dl?channel=release&platform=linux-{arch}&version={version}',
      'zotero-beta':  f'https://www.zotero.org/download/client/dl?channel=beta&platform=linux-{arch}',

      'jurism':       f'https://github.com/Juris-M/assets/releases/download/client%2Frelease%2F{version}/Jurism-{version}_linux-{arch}.tar.bz2',
      'jurism-beta':  f'https://our.law.nagoya-u.ac.jp/jurism/dl?channel=beta&platform=linux-{arch}',
    }[f'{self.client}{"-beta" if self.beta else ""}']

  @property
  def deb(self):
    return f'repo/{self.client}{self.apt.postfix}_{self.apt.version}{self.apt.patch}_{self.apt.arch}.deb'

  @property
  def tarball(self):
    return os.path.join(self.client, self.arch, self.version + '.tar.bz2')

  @property
  def apt(self):
    if self.beta:
      apt = Munch(
        postfix='-beta',
        version=self.version.replace('beta-', '').replace('-', '.'),
        patch='',
        arch=ArchMap[self.arch]
      )
    else:
      apt = Munch(
        postfix='',
        version=self.version,
        patch='',
        arch=ArchMap[self.arch]
      )
      if 'patch' in Config[self.client] and self.version in Config[self.client].patch:
        apt.patch = '-' + str(Config[self.client].patch[self.version])
    return apt
    
  def build(self):
    if not 'patch' in Config[self.client]: Config[self.client].patch = Munch()

    print(f'\n## building {self.deb}')
    self.rebuilt = True

    exists = None
    if args.rebuild:
      print('  forced rebuild')
    elif os.path.exists(self.deb):
      exists = f'  {self.deb} already exists'
    elif Repo and Repo.get(self.deb):
      exists = f'  {self.deb} re-fetched'
    if exists:
      try:
        # for some bloody reason Github frequently hands us a JSON description of the asset rather than the asset itself
        Dpkg(self.deb).headers
        print(exists)
        return
      except ArchiveFormatError:
        print(exists + ', but is corrupted')
        if os.path.exists(self.deb): os.remove(self.deb)

    if not os.path.exists(self.tarball) or args.reload:
      os.makedirs(os.path.dirname(self.tarball), exist_ok=True)
      print('  downloading', self.tarball)
      urlretrieve(self.url, self.tarball)

    if os.path.exists('build'): shutil.rmtree('build')
    os.makedirs('build')
  
    print(f'  unpacking {self.tarball}')
    tar = tarfile.open(self.tarball)
    for member in tar.getmembers():
      if not member.isreg(): continue
      member.name = re.sub(r'^.+?\/', '', member.name) # strip leading directory
  
      if member.name in ['zotero.desktop', 'jurism.desktop', 'active-update.xml', 'precomplete', 'removed-files', 'updates', 'updates.xml']:
        continue
  
      tar.extract(member, f'build/usr/lib/{self.client}{self.apt.postfix}')
    tar.close()
  
    print(f'  disable auto-update')
    with Open(f'build/usr/lib/{self.client}{self.apt.postfix}/defaults/pref/local-settings.js', 'a') as ls, Open(f'build/usr/lib/{self.client}{self.apt.postfix}/mozilla.cfg', 'a') as cfg:
      # enable mozilla.cfg
      if ls.tell() != 0: print('', file=ls)
      print('pref("general.config.obscure_value", 0); // only needed if you do not want to obscure the content with ROT-13', file=ls)
      print('pref("general.config.filename", "mozilla.cfg");', file=ls)

      # disable auto-update
      if cfg.tell() == 0:
        print('//', file=cfg)
      else:
        print('', file=cfg)
      print('lockPref("app.update.enabled", false);', file=cfg)
      print('lockPref("app.update.auto", false);', file=cfg)
  
    print(f'  write launcher entry')
    with Open(f'build/usr/share/applications/{self.client}{self.apt.postfix}.desktop', 'w') as f:
      desktop = configparser.RawConfigParser()
      desktop.add_section('Desktop Entry')
      desktop.optionxform=str
      desktop.set('Desktop Entry', 'Name', Config[self.client].name + self.apt.postfix.replace('-', ' '))
      desktop.set('Desktop Entry', 'Comment', Config[self.client].comment)
      desktop.set('Desktop Entry', 'Exec', f'/usr/lib/{self.client}{self.apt.postfix}/{self.client} --url %u')
      desktop.set('Desktop Entry', 'Icon', f'/usr/lib/{self.client}{self.apt.postfix}/chrome/icons/default/default256.png')
      desktop.set('Desktop Entry', 'Type', 'Application')
      desktop.set('Desktop Entry', 'Categories', Config[self.client].categories)
      desktop.set('Desktop Entry', 'StartupNotify', 'true')
      desktop.set('Desktop Entry', 'MimeType', ';'.join([mt for mi in MimeInfo.values() for mt in mi.mimetypes]))
      desktop.write(f, space_around_delimiters=False)

    print(f'  update mime info')
    with Open(f'build/usr/share/mime/packages/{self.client}{self.apt.postfix}.xml', 'wb') as f:
      E = ElementMaker(
        namespace='http://www.freedesktop.org/standards/shared-mime-info',
        nsmap={
          None : 'http://www.freedesktop.org/standards/shared-mime-info',
          'xml': 'http://www.w3.org/XML/1998/namespace',
        }
      )
      _mimetypes = []
      MIMETYPE = getattr(E, 'mime-type')
      MIMEINFO = getattr(E, 'mime-info')
      for name, mi in MimeInfo.items():
        if not 'extensions' in mi: continue

        children = [E.comment(name)]
        for k, v in mi.items():
          if len(k) == 2:
            children.append(E.comment(v, **{'{http://www.w3.org/XML/1998/namespace}lang': k}))
        for ext in mi.get('extensions', []):
          children.append(E.glob(pattern=f'*.{ext}'))
        for mt in mi.mimetypes[1:]:
          children.append(E.alias(type=mt))
        _mimetypes.append(MIMETYPE(*children, type=mi.mimetypes[0]))
      f.write(etree.tostring(MIMEINFO(*_mimetypes), pretty_print=True, xml_declaration=True, encoding='utf-8'))

    print(f'  write build control file')
    with Open('build/DEBIAN/control', 'w') as f:
      dependencies = ', '.join(sorted(list(set(Config[self.client].dependencies + ESR))))
      print(f'Package: {self.client}{self.apt.postfix}', file=f)
      print(f'Architecture: {self.apt.arch}', file=f)
      print(f'Depends: {dependencies}'.strip(), file=f)
      print(f'Maintainer: {Config.maintainer.email}', file=f)
      print(f'Section: {Config[self.client].section}', file=f)
      print('Priority: optional', file=f)
      print(f'Version: {self.apt.version}{self.apt.patch}', file=f)
      print(f'Description: {Config[self.client].description}', file=f)

    os.makedirs('build/usr/local/bin')
    os.symlink(f'/usr/lib/{self.client}{self.apt.postfix}/{self.client}', f'build/usr/local/bin/{self.client}{self.apt.postfix}')

    os.makedirs('repo', exist_ok=True)
    run(f'fakeroot dpkg-deb --build -Zgzip build {self.deb}')
    run(f'dpkg-sig -k {Config.maintainer.gpgkey} --sign builder {self.deb}')

#### deb builder ####

class Builder:
  def __init__(self):
    self.gather()
    self.cleanup()
    self.bump()
    self.build()
    self.trim()
    self.publish()

  def gather(self):
    # gather .debs to build
    for client in Clients:
      if client == 'zotero':
        versions = [release.version for release in load('https://www.zotero.org/download/client/manifests/release/updates-linux-x86_64.json', parse_json=True)]
      else:
        versions = []
        # jurism puts out new version in a frenzied burst -- only keep the last m-version
        for version in [release for release in load('https://github.com/Juris-M/assets/releases/download/client%2Freleases%2Fincrementals-linux/incrementals-release-linux').split('\n') if release != '']:
          if len(versions) == 0:
            versions.append(version)
          elif version.split('m')[0] == versions[-1].split('m')[0]:
            versions[-1] = version
          else:
            versions.append(version)
      versions.append(f'beta-{date.today().isoformat()}')

      for version in versions:
        for arch in ArchMap.keys():
          Deb(client, version, arch)

  def cleanup(self):
    # cleanup interrupted build
    for deb in glob.glob('repo/*.deb.*'):
      os.remove(deb)

    # cleanup leftover tarballs
    for client in Clients:
      for tarball in glob.glob(f'{client}/*/*.tar.bz2'):
        arch = os.path.basename(os.path.dirname(tarball))
        version = re.sub('-[0-9]+$', '', os.path.basename(tarball).replace('.tar.bz2', ''))
        if not any(deb for deb in Deb.select(client=client, version=version, arch=arch)):
          print('removing', tarball)
          os.remove(tarball)

  def bump(self):
    # bump patch level
    if args.bump:
      for client in Clients:
        debs = Deb.select(client=client, beta=False)
        if not 'patch' in Config[client]:
          Config[client].patch = Munch()
          Config[client].patch[debs[-1].version] = 0
        Config[client].patch[debs[-1].version] += 1
      with open('config.toml', 'w') as f:
        toml.dump(Config, f)
      sys.exit()

  def build(self):
    # build and download as needed

    if not args.rebuild and Repo and Repo.unchanged():
      print('\n## repo up to date')
      sys.exit()
    if Repo and Repo.rebuild: args.rebuild = True

    for deb in Deb.all():
      deb.build()

  def trim(self):
    # cleanup leftover .debs
    for deb in glob.glob('repo/*.deb'):
      client, version, aptarch = os.path.splitext(os.path.basename(deb))[0].split('_')[:3]
      if client.endswith('-beta'):
        version = 'beta-' + version.replace('.', '-')
        client = client.replace('-beta', '')
      if not any(d for d in Deb.select(client=client, version=version, aptarch=aptarch)):
        if os.path.exists('repo/Packages'): os.remove('repo/Packages')
        print('removing', deb)
        os.remove(deb)

  def publish(self):
    if Deb.rebuilt or not os.path.exists('repo/Packages'):
      print(f'\n## preparing repo')
      run(f'gpg --armor --export {Config.maintainer.gpgkey} > repo/deb.gpg.key')
      run(f'cd repo && apt-ftparchive packages . > Packages')
      run(f'bzip2 -kf repo/Packages')
      run(f'cd repo && apt-ftparchive release . > Release')
      run(f'gpg --yes -abs -u {Config.maintainer.gpgkey} -o repo/Release.gpg --digest-algo sha256 repo/Release')
      run(f'gpg --yes -abs -u {Config.maintainer.gpgkey} --clearsign -o repo/InRelease --digest-algo sha256 repo/Release')

      if Repo:
        with open('repo/install.sh', 'w') as install, open('install.sh') as tmpl:
          install.write(Template(tmpl.read()).substitute(url=Repo.url))
      else:
        if os.path.exists('repo/install.sh'): os.remove('repo/install.sh')

      if Repo:
        Repo.publish()
        print(f'::set-output name=url::{Repo.url}')
        print('::set-output name=rebuilt::true')
      else:
        print(f'\n## not publishing repo: no repo specified')
    else:
      print(f'\n## not publishing repo: nothing rebuilt')

Builder()
